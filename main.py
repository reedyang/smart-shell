#!/usr/bin/env python3
"""
æ–‡ä»¶ç®¡ç†AI Agentä¸»å¯åŠ¨è„šæœ¬

ç”¨æ³•ï¼š
    python main.py       # ä½¿ç”¨é»˜è®¤AIæ¨¡å‹
    python main.py model # ä½¿ç”¨æŒ‡å®šçš„AIæ¨¡å‹
"""

import sys
import json
import os
from pathlib import Path

# æ·»åŠ agentç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
agent_dir = current_dir / "agent"
sys.path.insert(0, str(agent_dir))

from agent.file_manager_agent import FileManagerAgent

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨æ–‡ä»¶ç®¡ç†AI Agent...")
    
    work_directory = None
    # å‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆï¼Œè‹¥æœ‰å‚æ•°åˆ™ç›´æ¥ç”¨ä¸ºollamaæ¨¡å‹å¹¶å¿½ç•¥é…ç½®æ–‡ä»¶
    if len(sys.argv) > 1:
        model_name = sys.argv[1]
        provider = "ollama"
        params = None
        config = None
    else:
        config = None
        config_path = None
        # ä¼˜å…ˆæŸ¥æ‰¾ç”¨æˆ·ä¸»ç›®å½•ä¸‹çš„llm-filemgr.json
        user_home = str(Path.home())
        user_config = os.path.join(user_home, "llm-filemgr.json")
        local_config = os.path.join(current_dir, "llm-filemgr.json")
        if os.path.exists(user_config):
            config_path = user_config
        elif os.path.exists(local_config):
            config_path = local_config
        if config_path:
            try:
                with open(config_path, "r", encoding="utf-8") as f:
                    config = json.load(f)
            except Exception as e:
                print(f"âš ï¸ é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
                config = None
        # é»˜è®¤æ¨¡å‹
        model_name = "gemma3:4b"
        provider = "ollama"
        params = None
        if config:
            provider = config.get("provider", "ollama").lower()
            params = config.get("params")
            if provider in ("openai", "openwebui") and params:
                model_name = params.get("model", "gpt-3.5-turbo")
            elif provider == "ollama":
                pass

    # é€‰æ‹©æ¨¡å‹æä¾›æ–¹
    if provider == "openai" and params:
        print(f"ğŸ¤– ä½¿ç”¨OpenAI API: {params.get('base_url', 'https://api.openai.com/v1')} æ¨¡å‹: {model_name}")
        try:
            agent = FileManagerAgent(
                model_name=model_name,
                work_directory=work_directory,
                provider="openai",
                params=params
            )
            agent.run()
            return 0
        except Exception as e:
            print(f"âŒ OpenAI APIæ¨¡å¼è¿è¡Œé”™è¯¯: {str(e)}")
            return 1
    elif provider == "openwebui" and params:
        print(f"ğŸ¤– ä½¿ç”¨OpenWebUI API: {params.get('base_url', 'http://localhost:8080/v1')} æ¨¡å‹: {model_name}")
        try:
            agent = FileManagerAgent(
                model_name=model_name,
                work_directory=work_directory,
                provider="openwebui",
                params=params
            )
            agent.run()
            return 0
        except Exception as e:
            print(f"âŒ OpenWebUI APIæ¨¡å¼è¿è¡Œé”™è¯¯: {str(e)}")
            return 1
    else:
        # é»˜è®¤ollamaæœ¬åœ°
        try:
            import ollama
            models = ollama.list()
            available_models = []
            for model in models.get('models', []):
                if hasattr(model, 'model'):
                    available_models.append(model.model)
                elif isinstance(model, dict):
                    available_models.append(model.get('name', model.get('model', 'unknown')))
                else:
                    available_models.append(str(model))
            print(f"ğŸ“‹ å¯ç”¨æ¨¡å‹: {available_models}")
            if model_name not in available_models:
                print(f"âš ï¸ æŒ‡å®šæ¨¡å‹ {model_name} ä¸å¯ç”¨")
                if available_models:
                    model_name = available_models[0]
                    print(f"ğŸ’¡ ä½¿ç”¨é»˜è®¤æ¨¡å‹: {model_name}")
                else:
                    print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
                    return 1
        except ImportError:
            print("âŒ è¯·å…ˆå®‰è£… ollama åŒ…: pip install ollama")
            return 1
        except Exception as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ°Ollama: {str(e)}")
            print("è¯·ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ")
            return 1
        try:
            agent = FileManagerAgent(
                model_name=model_name,
                work_directory=work_directory,
                provider="ollama"
            )
            agent.run()
            return 0
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
            return 0
        except Exception as e:
            print(f"âŒ è¿è¡Œé”™è¯¯: {str(e)}")
            return 1

if __name__ == "__main__":
    sys.exit(main()) 